# Contributing 

Thank you for your interest in contributing to this repository! This project is meant to show how to probe an LLM application for more than its proficiency at its main task, using Open Source libraries. Specifically, it's meant to show how to probe for AI/LLM-speicific vulnerabilities using Open Source libraries.

Contributions are very welcome:
* Extending code or documentation
* Filing bug reports
* Suggesting other (Open Source) libraries to use
* Or simply reaching out and saying what would help **you** understand what the libraries do for you and why the repo does what it does.
